services:
  postgresql:
    image: postgres:15.5
    container_name: postgresql
    restart: unless-stopped
    environment:
      POSTGRES_PASSWORD: "${PROJECT_PASSWORD}"
    volumes:
      - ./sql:/docker-entrypoint-initdb.d
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "${POSTGRES_PORT}:${POSTGRES_PORT}"
    networks: [data-network]
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres", "-d", "${POSTGRES_DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 30s
    mem_limit: 1200m

  mongodb:
    image: mongo:6.0
    container_name: mongodb
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: "${PROJECT_USER}"
      MONGO_INITDB_ROOT_PASSWORD: "${PROJECT_PASSWORD}"
      MONGO_INITDB_DATABASE: "${MONGO_DATABASE_NAME}"
    volumes:
      - mongodb_data:/data/db
    ports:
      - "${MONGO_PORT}:${MONGO_PORT}"
    networks: [data-network]
    healthcheck:
      test: ["CMD", "mongosh", "--host", "localhost", "--username", "${PROJECT_USER}", "--password", "${PROJECT_PASSWORD}", "--authenticationDatabase", "admin", "--eval", "db.runCommand('ping').ok", "--quiet"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 120s
    mem_limit: 1024m

  minio:
    image: minio/minio:RELEASE.2025-04-22T22-12-26Z
    container_name: minio
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: "${PROJECT_USER}"
      MINIO_ROOT_PASSWORD: "${PROJECT_PASSWORD}"
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    ports:
      - "${MINIO_PORT}:${MINIO_PORT}"
      - "9001:9001"
    networks: [data-network]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${MINIO_PORT}/minio/health/live"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 15s
    mem_limit: 512m

  kafka:
    image: bitnami/kafka:3.7
    container_name: kafka
    restart: unless-stopped
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
    ports:
      - "9092:9092"
      - "9093:9093"
    volumes:
      - kafka_data:/bitnami/kafka
    networks: [data-network]
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --list --bootstrap-server localhost:9092 || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 30s
    mem_limit: 1536m

  orchestration_ui:
    build:
      context: ..
      dockerfile: ./docker/orchestration_ui.dockerfile
    container_name: orchestration_ui
    restart: unless-stopped
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_healthy
      minio:
        condition: service_healthy
    environment:
      MONGO_HOST: "${MONGO_HOST}"
      MONGO_PORT: "${MONGO_PORT}"
      MONGO_USER: "${PROJECT_USER}"
      MONGO_PASSWORD: "${PROJECT_PASSWORD}"
      MONGO_DB: "${MONGO_DATABASE_NAME}"
      MINIO_HOST: "${MINIO_HOST}"
      MINIO_PORT: "${MINIO_PORT}"
      MINIO_USER: "${PROJECT_USER}"
      MINIO_PASSWORD: "${PROJECT_PASSWORD}"
      MINIO_CLIENT_GAMMA_STORAGE_BUCKET: "${MINIO_CLIENT_GAMMA_STORAGE_BUCKET}"
      KAFKA_BOOTSTRAP_SERVERS: "${KAFKA_BOOTSTRAP_SERVERS}"
      KAFKA_CLIENT_BETA_STORAGE_TOPIC: "${KAFKA_CLIENT_BETA_STORAGE_TOPIC}"
      CHUNK_SIZE: 10000
      SQLITE_DB_FILE: "/app/storage/orchestrator.db"
    volumes:
      - orchestration_ui_data:/app
      - ../generators:/app/scripts/support_insights
      - ./entrypoint/data_generator_orchestrator.py:/app/scripts/python_scripts_orchestrator/data_generator_orchestrator.py
      - ./entrypoint/orchestration_ui_startup.sh:/app/orchestration_ui_startup.sh
      - ./entrypoint/sqlite3_db_setup.sql:/app/sqlite3_db_setup.sql
    ports:
      - "1212:1212"
    command: bash /app/orchestration_ui_startup.sh
    healthcheck:
      test: ["CMD", "curl", "-f", "localhost:1212"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks: [data-network]
    mem_limit: 1024m

  airflow:
    build:
      context: ..
      dockerfile: ./docker/airflow.dockerfile
    container_name: airflow
    restart: unless-stopped
    depends_on:
      postgresql:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW_LOAD_EXAMPLES: "False"
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
      AIRFLOW__LOGGING__LOGGING_LEVEL: INFO
      AIRFLOW_USERNAME: "${PROJECT_USER}"
      AIRFLOW_PASSWORD: "${PROJECT_PASSWORD}"
      AIRFLOW_FIRSTNAME: "${FIRST_NAME}"
      AIRFLOW_LASTNAME: "${LAST_NAME}"
      AIRFLOW_EMAIL: "${EMAIL_ADDRESS}"
      AIRFLOW_DATABASE_NAME: "${AIRFLOW_METADATA_DATABASE}"
      AIRFLOW_DATABASE_USERNAME: "${POSTGRES_DEFAULT_USER}"
      AIRFLOW_DATABASE_PASSWORD: "${PROJECT_PASSWORD}"
      AIRFLOW_DATABASE_HOST: "${POSTGRES_HOST}"
      AIRFLOW_DATABASE_PORT_NUMBER: "${POSTGRES_PORT}"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_DEFAULT_USER}:${PROJECT_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${AIRFLOW_METADATA_DATABASE}
      AIRFLOW__DATABASE__CONN_MAX_AGE: 30
      AIRFLOW__CORE__PARALLELISM: 12
      AIRFLOW__CORE__DAG_CONCURRENCY: 10
      AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG: 1
      AIRFLOW__CORE__MAX_ACTIVE_RUNS: 10
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${PROJECT_USER}
      _AIRFLOW_WWW_USER_PASSWORD: ${PROJECT_PASSWORD}
      AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.session
      AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
    volumes:
      - ../airflow/dags:/opt/airflow/dags
      - ../airflow/plugins:/opt/airflow/plugins
      - ./entrypoint/postgresql-jdbc.jar:/opt/spark/jars/postgresql-jdbc.jar
      - airflow_logs:/opt/airflow/logs
    ports:
      - "8080:8080"
    command: >
      bash -c "
      airflow scheduler --daemon & \
      airflow triggerer --daemon & \
      airflow dag-processor & \
      airflow api-server"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 60s
    networks: [data-network]
    mem_limit: 10240m

  superset:
    build:
      context: ..
      dockerfile: ./docker/superset.dockerfile
    container_name: superset
    restart: unless-stopped
    depends_on:
      postgresql:
        condition: service_healthy
    environment:
      SUPERSET_PORT: 8088
      SUPERSET_SECRET_KEY: ${PROJECT_PASSWORD}
      SUPERSET_DATABASE_DIALECT: postgresql+psycopg2
      SUPERSET_DATABASE_USER: postgres
      SUPERSET_DATABASE_PASSWORD: ${PROJECT_PASSWORD}
      SUPERSET_DATABASE_HOST: ${POSTGRES_HOST}
      SUPERSET_DATABASE_PORT_NUMBER: ${POSTGRES_PORT}
      SUPERSET_DATABASE_NAME: ${SUPERSET_METADATA_DATABASE}
      FIRST_NAME: ${FIRST_NAME}
      LAST_NAME: ${LAST_NAME}
      EMAIL_ADDRESS: ${EMAIL_ADDRESS}
      PROJECT_USER: ${PROJECT_USER}
      PROJECT_PASSWORD: ${PROJECT_PASSWORD}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      SUPERSET_METADATA_DATABASE: ${SUPERSET_METADATA_DATABASE}
    volumes:
      - ../superset/exports:/app/exports
      - ./entrypoint/superset_startup.sh:/app/superset_startup.sh
    ports:
      - "8088:8088"
    command: bash /app/superset_startup.sh
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    networks: [data-network]
    mem_limit: 1024m

volumes:
  postgres_data:
  mongodb_data:
  minio_data:
  kafka_data:
  orchestration_ui_data:
  airflow_logs:

networks:
  data-network:
    driver: bridge
